{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подключаем библиотеки и загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CICIDS2017.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если в наборе данных несколько типов аномалий, столбец с метками может содержать строки (например, 'BENIGN', 'DoS', 'DDoS', и т.п.)\n",
    "# Преобразуем метки в числовой формат\n",
    "le = LabelEncoder()\n",
    "data['Label'] = le.fit_transform(data['Label'])\n",
    "\n",
    "# Отделяем признаки от целевой переменной\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# Разбиваем данные на обучающую и тестовую выборки (20% на тест)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подбираем параметры для классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Определяем пространство гиперпараметров\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10.0),\n",
    "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 1e-9, 10.0),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0.0, 1.0),\n",
    "        'verbose': 0,  # отключаем вывод обучения\n",
    "        # Если классификация мультиклассовая, выбираем соответствующую функцию потерь\n",
    "        'loss_function': 'MultiClass' if len(np.unique(y)) > 2 else 'Logloss'\n",
    "    }\n",
    "    \n",
    "    # Инициализируем модель с подобранными гиперпараметрами\n",
    "    model = CatBoostClassifier(**params, random_state=42)\n",
    "    \n",
    "    # Используем StratifiedKFold для кросс-валидации (3 фолда)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, valid_idx in cv.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "        model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)],\n",
    "                  early_stopping_rounds=50, verbose=False)\n",
    "        preds = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, preds)\n",
    "        scores.append(acc)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучаем CatBoost используя Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # число итераций можно увеличить для лучшего поиска\n",
    "\n",
    "print(\"Лучшая оптимизация:\")\n",
    "best_trial = study.best_trial\n",
    "print(\"  Лучший результат (accuracy):\", best_trial.value)\n",
    "print(\"  Лучшие гиперпараметры:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_trial.params.copy()\n",
    "best_params.update({\n",
    "    'verbose': 0,\n",
    "    'loss_function': 'MultiClass' if len(np.unique(y)) > 2 else 'Logloss',\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nТочность на тестовой выборке: {:.4f}\".format(accuracy))\n",
    "\n",
    "print(\"\\nОтчёт по классификации:\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_.astype(str)))\n",
    "\n",
    "print(\"Матрица ошибок:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigData_lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
